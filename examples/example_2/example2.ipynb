{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fd153b-7ae2-4bc5-9a89-9960caa571a2",
   "metadata": {},
   "source": [
    "# Example 2 - Training on one data set - evaluating on another\n",
    "\n",
    "In this example, we use experimental AST data to train the model. Then, we import another dataset, and use the trained PINN to predict electrolyzer performance degradation based on the previously learned weights and biases.\n",
    "\n",
    "First, we define the project root and append the source folder for importing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec56b1-34bb-4311-91cb-582f51d94137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the root project folder\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "# Add the src folder to sys.path\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6608add-6fb9-4b9b-8c4d-6c8cb72bf690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from elec_pinn.data.preprocessing   import Preprocessor     \n",
    "from elec_pinn.data.loader          import ScalerLoader     \n",
    "from elec_pinn.cli                  import load_config, get_model\n",
    "from elec_pinn.utils.visualization  import plot_pinn_performance \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba50b7-7834-468c-885a-80af2ea6e67b",
   "metadata": {},
   "source": [
    "Load the configurations from the config.yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50569b99-69a3-4b4e-a655-5e5f5ecbde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"example2_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e9d5b-d84d-4807-aea5-953018b6e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5dc49f-2508-469d-859e-8f5dee66f561",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3fddb-a6fd-4a41-94f5-de24176f1549",
   "metadata": {},
   "source": [
    "We load the data into the preproccessor, which fits electrolyzer performance based on the initial part of the dataset - as defined in the config.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab1937a-2c48-4a84-938d-c4f70286e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = Preprocessor(cfg[\"data\"][\"dataset_name\"])\n",
    "df = dp.preprocess(\n",
    "                    t0 = cfg[\"data\"][\"t0\"],\n",
    "                    t1 = cfg[\"data\"][\"t1\"],\n",
    "                    plot_fit = True,   # show the performance fit curve\n",
    "                    plot_raw = False   # show raw data over time\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed953fb5-5f15-4e6c-9626-1a526cceaf26",
   "metadata": {},
   "source": [
    "Intiantiate a 'scaler' based on feature and targetnames as well as the scaling range. Then, use the .get_loader() method to convert the input data into Pytorch DataLoaders that are useful when working with neural networks. Here, the dataset is split into train, validation, test, and lastly a combined dataloader, where the combined DataLoader contains the whole dataset.\n",
    "\n",
    "The training DataLoader is shuffled in time while the validation, testing and all (combined) dataloaders are not shuffled in time. The shuffling was found to enhance prediction accuracy by trial-and-error.\n",
    "\n",
    "The resulting dataloaders are also normalized to the range specified in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae005f01-34de-4ab3-bcac-1941de950970",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ScalerLoader(\n",
    "                feature_cols=cfg[\"data\"][\"feature_names\"],\n",
    "                target_cols=cfg[\"data\"][\"target_names\"],\n",
    "                scale_range=tuple(cfg[\"data\"][\"scale_range\"]) \n",
    "                     ).fit(df)\n",
    "\n",
    "train_loader, val_loader, test_loader, all_loader = scaler.get_loaders(\n",
    "    df,\n",
    "    f_train=cfg[\"data\"][\"train_frac\"],\n",
    "    f_val=  cfg[\"data\"][\"val_frac\"],\n",
    "    f_test=1 - cfg[\"data\"][\"train_frac\"] - cfg[\"data\"][\"val_frac\"],\n",
    "    batch_sizes=tuple(cfg[\"training\"][\"batch_sizes\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e987da9c-6978-48e6-a0e4-1d32c0861e8c",
   "metadata": {},
   "source": [
    "We then pull the requested PINN version. In this example we use the FullPINN containing all the prediction functionalities. Next, the model is trained using the training and validation loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52991ade-b2eb-4b30-8f08-206d615f571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model   = get_model(cfg)\n",
    "training_results = model.train_model( train_loader, \n",
    "                                      val_loader,\n",
    "                                      cfg['training']['epochs'],\n",
    "                                      cfg['training']['save_freq'],\n",
    "                                      cfg['training']['patience'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2a806b-15ba-4ed4-95a0-bdacf8ed4c9c",
   "metadata": {},
   "source": [
    "Next, we can use the plot_losses method to inspect the training process and store the results in the example_2 directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efa0e9-6ae1-48c7-a288-cf72ad9045d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to evaluate the model performance on the training dataset\n",
    "save_path = os.path.join(project_root, \"examples\", \"example_2\")\n",
    "model.plot_losses( save_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691abdc-7b0c-4055-9101-7553b00fe4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e037164a-cb40-40bc-9936-8935e421dad8",
   "metadata": {},
   "source": [
    "Next, we evaluate model performance to gauge whether the trained model is able to accurately mimic the training and validation data. In this example, a large part of the dataset is used for training and validation, and thus we expect the PINN to accurately model the training & validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6ed80-e94c-49f8-9427-53934bac1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = model.evaluate(scaler, df, all_loader, cfg['data']['feature_names'], cfg['data']['target_names'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7dd139-edfe-44ff-95e3-504a948fa8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pinn_performance(result_df, cfg['data']['feature_names'], cfg['data']['target_names'], train_frac = cfg[\"data\"][\"train_frac\"], val_frac = cfg[\"data\"][\"val_frac\"], save_path = save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c19e8-a4ec-4a4b-a18f-431177b974ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32bc8cd5-387f-4163-ad9b-942fb85aa013",
   "metadata": {},
   "source": [
    "At this point we have trained the PINN on a dataset. We then want to evaluate how this specific cell would perform if we gave it another test protocol. For this purpose, we now test the case where the cell is operating based on the solar PV profile. \n",
    "\n",
    "The \"SolarPV_synthethic_electrolyzer_data.csv\" file contains ~6 months of solar PV data normalized to current density values similar to what is contained in the original trainind dataset.\n",
    "First, we initiate a new data Preprocessor for the new forecasting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca16b0-cd03-481f-9eb7-c1e1dc6f5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp = Preprocessor(\"SolarPV_synthethic_electrolyzer_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586601e6-8fbf-4d14-ab45-3d256dab9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp.load() # loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a704963-4945-42dc-9446-fbf440a32307",
   "metadata": {},
   "source": [
    "Using the previous training datasset (\"df\"), we can still fit performance data on the new test protocol even though it does not contain any cell voltages. This is done by specifying fitting_df = df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f26ac-e87e-42bd-b9f3-04afae23f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = fdp.fit_performance( t0 = cfg[\"data\"][\"t0\"],\n",
    "                    t1 = cfg[\"data\"][\"t1\"],\n",
    "                    fitting_df = df )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6bdc3-e85c-4402-bd0d-cc5fb1624361",
   "metadata": {},
   "source": [
    "We inspect that the new forecast_df does indeed contain the performance cell voltage for all time values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf98f0-5fbc-415e-b692-0d68d1ab5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(forecast_df['t'], forecast_df['U_perf'], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a7a8b-2253-41ef-acf8-33adea33237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to use the same scaler from before, so the data is scaled in an identical way\n",
    "\n",
    "forecast_loader = scaler.get_inference_loader(\n",
    "    forecast_df,\n",
    "    batch_size=cfg[\"training\"][\"batch_sizes\"][0] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133bf3a2-6aba-491a-a60a-213f179fd916",
   "metadata": {},
   "source": [
    "Now we can run the model.evaluate() method using the new forecast_df and forecast_loader to evaluate the model prediction on the new dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d130d2a-a1c9-44ea-8c3e-dbee3c0a4923",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_result_df = model.evaluate(scaler, forecast_df, forecast_loader, cfg['data']['feature_names'], cfg['data']['target_names'], save_folder = \"forecast_plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef10815-c5bd-47cb-83a5-5bb5005528a9",
   "metadata": {},
   "source": [
    "Lastly, we can plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fbda8-933a-418a-9243-d9aff8e18eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pinn_performance(forecast_result_df, cfg['data']['feature_names'], cfg['data']['target_names'], train_frac = 0.0, val_frac = 0.0, save_path = save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
